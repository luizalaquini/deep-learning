{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1dGf1PXVo2I"
      },
      "source": [
        "# Aula 1 - Rede Neural Artificial sem pacotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCYWCu3OW5gy"
      },
      "source": [
        "### Classe que permite a criação da rede"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHUvpXUjCBlZ"
      },
      "source": [
        "Nesta aula, vamos explorar o funcionamento básico de uma Rede Neural Artificial (RNA) implementando uma do zero, sem utilizar pacotes prontos como TensorFlow ou PyTorch. Isso permitirá que você entenda o que acontece internamente em uma rede neural e os cálculos que ela realiza para ajustar pesos e gerar previsões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3LzUkmHXCrW"
      },
      "source": [
        "Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p-jQaaq5OyYv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENyDkGAjO2uo"
      },
      "source": [
        "# Parte 1 - Parâmetros básicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFNjgF-4DyDF"
      },
      "source": [
        "Definimos um valor de seed (np.random.seed(0)) para garantir a reprodutibilidade dos resultados. Isso assegura que o processo de inicialização de pesos e a divisão de dados ocorra da mesma forma a cada execução, essencial para depuração e análise de desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zmSPDTP-O0IT"
      },
      "outputs": [],
      "source": [
        "# Garante que os resultados sejam reproduzíveis. Trata-se do valor utilizado para iniciar operações randômicas.\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C2EX8zaO58D"
      },
      "source": [
        "# Parte 2 - Preparação dos Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKas0hyGCOVj"
      },
      "source": [
        "Carregamos os dados e realizamos algumas operações para preparar o conjunto de entrada e saída da rede neural:\n",
        "\n",
        "**Carregamento do Dataset**: Utilizamos pd.read_csv(\"winequality-red.csv\") para ler o arquivo CSV de dados. É importante garantir que o arquivo esteja formatado corretamente para evitar problemas de leitura e análise.\n",
        "\n",
        "**Definição de Entradas e Saídas (X e Y)**: Definimos x como as primeiras 11 colunas, que contêm as variáveis preditoras, e y como a coluna de destino (qualidade do vinho).\n",
        "\n",
        "**Normalização**: Aplicamos normalização min-max a cada coluna do conjunto de dados de entrada x, convertendo os valores para a faixa entre 0 e 1. Isso facilita o aprendizado da rede, evitando que valores muito altos dominem as operações de peso.\n",
        "\n",
        "**Divisão do Dataset**: Dividimos o conjunto de dados em x_train, x_test, y_train e y_test usando train_test_split, com 20% dos dados reservados para teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H7Pbf-A7O8X4"
      },
      "outputs": [],
      "source": [
        "# Lê nossos dados de vinho\n",
        "data = pd.read_csv(\"data/winequality-red.csv\")\n",
        "\n",
        "# X e Y\n",
        "x = data.iloc[:, 0:11]\n",
        "y = data.iloc[:, 11]\n",
        "\n",
        "# Função para normalização min-max\n",
        "def min_max_normalization(column):\n",
        "    min_val = column.min()\n",
        "    max_val = column.max()\n",
        "    normalized_column = (column - min_val) / (max_val - min_val)\n",
        "    return normalized_column\n",
        "\n",
        "# Normalizar todas as colunas do DataFrame\n",
        "x = x.apply(min_max_normalization)\n",
        "\n",
        "y = min_max_normalization(y)\n",
        "\n",
        "# Train Test Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTL8StZDEDRh"
      },
      "source": [
        "Definimos os tamanhos das camadas da rede:\n",
        "\n",
        "**input_size**: Define o número de neurônios na camada de entrada, igual ao número de colunas em x_train.\n",
        "\n",
        "**hidden_size**: Número de neurônios na camada oculta, determinado aqui como 4. Isso pode ser ajustado dependendo da complexidade do modelo e dos dados.\n",
        "\n",
        "**output_size**: Número de neurônios na camada de saída, que é 1, pois estamos tentando prever a qualidade do vinho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KnuDtz2ZH2ps"
      },
      "outputs": [],
      "source": [
        "# Parâmetros da rede neural\n",
        "input_size = x_train.shape[1]\n",
        "hidden_size = 4\n",
        "output_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRCQeubTYWiC",
        "outputId": "838f4d10-7641-4c90-ffe2-22b6e32e88da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46cxGfw6QMkc"
      },
      "source": [
        "# Parte 3 - Inicializa Parâmetros randomicamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u1O-KlDEMrN"
      },
      "source": [
        "Nesta etapa, inicializamos os pesos da rede neural aleatoriamente:\n",
        "\n",
        "Função **initialize_parameters**: Define os pesos da camada de entrada para a camada oculta (weights_input_hidden) e da camada oculta para a camada de saída (weights_hidden_output). Pesos aleatórios ajudam a evitar simetrias e facilitam a convergência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L5aeYO0bQPU2"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(input_size, hidden_size, output_size):\n",
        "    np.random.seed(0)\n",
        "    weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "    weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "    return weights_input_hidden, weights_hidden_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V1NkSrkQHkZ9"
      },
      "outputs": [],
      "source": [
        "weights_input_hidden, weights_hidden_output =  initialize_parameters(input_size, hidden_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
              "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
              "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351],\n",
              "       [ 0.76103773,  0.12167502,  0.44386323,  0.33367433],\n",
              "       [ 1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
              "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n",
              "       [ 2.26975462, -1.45436567,  0.04575852, -0.18718385],\n",
              "       [ 1.53277921,  1.46935877,  0.15494743,  0.37816252],\n",
              "       [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n",
              "       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
              "       [-1.04855297, -1.42001794, -1.70627019,  1.9507754 ]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights_input_hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.50965218],\n",
              "       [-0.4380743 ],\n",
              "       [-1.25279536],\n",
              "       [ 0.77749036]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights_hidden_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7c0waIPRsHN"
      },
      "source": [
        "# Parte 4 - Função Sigmoide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6XWX9hUET0G"
      },
      "source": [
        "A função sigmoide é aplicada para transformar as saídas dos neurônios:\n",
        "\n",
        "**sigmoid**: Função de ativação que aplica uma transformação para produzir uma saída entre 0 e 1.\n",
        "\n",
        "**sigmoid_derivative**: Função derivada da sigmoide, usada durante o cálculo da retropropagação para ajustar os pesos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RrcG56nvRucd"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toevu8CuR9OF"
      },
      "source": [
        "# Parte 5 - Forward Propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6gcv9UGEYJo"
      },
      "source": [
        "Realizamos a propagação direta para calcular as previsões da rede neural:\n",
        "\n",
        "Função **forward_pass**: Multiplicamos a entrada pela matriz de pesos de entrada para camada oculta e aplicamos a função de ativação sigmoide. A saída é então multiplicada pela matriz de pesos da camada oculta para a saída, resultando na previsão final.\n",
        "\n",
        "Essa etapa gera o output, a previsão da rede para cada exemplo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SN90WsTYR__l"
      },
      "outputs": [],
      "source": [
        "def forward_pass(inputs, weights_input_hidden, weights_hidden_output):\n",
        "    hidden_layer_input = np.dot(inputs, weights_input_hidden)\n",
        "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
        "\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output)\n",
        "    output = sigmoid(output_layer_input)\n",
        "\n",
        "    return output, hidden_layer_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h7BVCZ6mLY86"
      },
      "outputs": [],
      "source": [
        "output, hidden_output = forward_pass(x_train,weights_input_hidden, weights_hidden_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xT1KbDDScue"
      },
      "source": [
        "# Parte 6 - Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZaAWFVbEeCD"
      },
      "source": [
        "Nesta etapa, ajustamos os pesos com base no erro da previsão:\n",
        "\n",
        "**Erro de Saída**: Calculado como a diferença entre a previsão (output) e o valor real (targets).\n",
        "\n",
        "**Gradientes**: Calculamos os gradientes para ajustar os pesos usando as derivadas da função de ativação. output_delta ajusta a camada de saída, enquanto hidden_delta ajusta a camada oculta.\n",
        "\n",
        "**Atualização dos Pesos**: Calculamos os gradientes para os pesos entre as camadas de entrada e oculta, e entre as camadas oculta e de saída. Esses gradientes são ajustados de acordo com a taxa de aprendizado (learning_rate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b3fb7LTfShev"
      },
      "outputs": [],
      "source": [
        "def backward_pass(inputs, targets, output, hidden_output, weights_input_hidden, weights_hidden_output,\n",
        "                  learning_rate):\n",
        "    output_error = targets - output\n",
        "    output_delta = output_error * sigmoid_derivative(output)\n",
        "\n",
        "    hidden_error = np.dot(output_delta, weights_hidden_output.T)\n",
        "    hidden_delta = hidden_error * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    weights_input_hidden_grad = np.dot(inputs.T, hidden_delta) * learning_rate\n",
        "    weights_hidden_output_grad = np.dot(hidden_output.T, output_delta) * learning_rate\n",
        "\n",
        "    return weights_input_hidden_grad, weights_hidden_output_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgdr6zm2Wrwb",
        "outputId": "9365936b-ade3-47d2-9831-57baf4a41ed1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1279,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zyBn7O-AQCfd"
      },
      "outputs": [],
      "source": [
        "# Nova rede\n",
        "learning_rate = 0.01\n",
        "\n",
        "weights_input_hidden_grad, weights_hidden_output_grad =  backward_pass(x_train, y_train.to_numpy().reshape(-1, 1), output, hidden_output, weights_input_hidden, weights_hidden_output,learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHLmJShBXOU0",
        "outputId": "168cfb3d-dc20-4ff8-c8a9-69ec1922825f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-0.01355822, -0.01890645, -0.05582903,  0.01543676],\n",
              "       [-0.0098772 , -0.01219036, -0.0372528 ,  0.01349915],\n",
              "       [-0.01230602, -0.01665081, -0.04911258,  0.0123021 ],\n",
              "       [-0.00455585, -0.00601904, -0.01786188,  0.00562977],\n",
              "       [-0.00469891, -0.00628142, -0.01871869,  0.00629653],\n",
              "       [-0.00944996, -0.01041949, -0.03173739,  0.01168193],\n",
              "       [-0.00545352, -0.00658387, -0.02021572,  0.0075366 ],\n",
              "       [-0.01885934, -0.02553933, -0.07570145,  0.02398096],\n",
              "       [-0.01910817, -0.02141004, -0.06646448,  0.0229312 ],\n",
              "       [-0.00903952, -0.01131357, -0.0343927 ,  0.01080971],\n",
              "       [-0.01600269, -0.01711152, -0.05407832,  0.01563747]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights_input_hidden_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAhGU8B3XRVV",
        "outputId": "b832d545-07a3-4478-9cf0-c256a3f0b415"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
              "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
              "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351],\n",
              "       [ 0.76103773,  0.12167502,  0.44386323,  0.33367433],\n",
              "       [ 1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
              "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n",
              "       [ 2.26975462, -1.45436567,  0.04575852, -0.18718385],\n",
              "       [ 1.53277921,  1.46935877,  0.15494743,  0.37816252],\n",
              "       [-0.88778575, -1.98079647, -0.34791215,  0.15634897],\n",
              "       [ 1.23029068,  1.20237985, -0.38732682, -0.30230275],\n",
              "       [-1.04855297, -1.42001794, -1.70627019,  1.9507754 ]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weights_input_hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAgd8LYDVyxB"
      },
      "source": [
        "# Parte 7 - Treina Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JPhw0elEnUi"
      },
      "source": [
        "Usamos o processo de propagação direta e retropropagação repetidamente para treinar a rede neural:\n",
        "\n",
        "**Função train_neural_network**: Realiza a propagação direta e a retropropagação em cada época. Calculamos a perda e a acurácia em cada época, permitindo observar o desempenho ao longo do tempo.\n",
        "\n",
        "**Epochs e Aprendizado**: Definimos o número de épocas (iterações) e a taxa de aprendizado. No treinamento, os pesos são atualizados em cada época, reduzindo o erro.\n",
        "\n",
        "**Visualização de Perda**: Armazenamos e imprimimos a perda em épocas específicas para acompanhar a performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l1jXabZFVyNo"
      },
      "outputs": [],
      "source": [
        "def train_neural_network(x_train, y_train, input_size, hidden_size, output_size, epochs, learning_rate):\n",
        "    weights_input_hidden, weights_hidden_output = initialize_parameters(input_size, hidden_size, output_size)\n",
        "\n",
        "    # Listas para armazenar a perda e a acurácia em cada época\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        output, hidden_output = forward_pass(x_train, weights_input_hidden, weights_hidden_output)\n",
        "        weights_input_hidden_grad, weights_hidden_output_grad = \\\n",
        "            backward_pass(x_train, y_train, output, hidden_output, weights_input_hidden,\n",
        "                          weights_hidden_output, learning_rate)\n",
        "\n",
        "        # Atualização dos pesos\n",
        "        weights_input_hidden += weights_input_hidden_grad\n",
        "        weights_hidden_output += weights_hidden_output_grad\n",
        "\n",
        "        # Calcular e armazenar a perda e a acurácia em cada época\n",
        "        loss = np.mean(np.square(y_train - output))\n",
        "        losses.append(loss)\n",
        "\n",
        "        if epoch % 1000 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss = {loss}\")\n",
        "\n",
        "    return losses, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zol5xjILXd2j",
        "outputId": "03cf86d1-fb28-4ab0-e2b0-051f13cbcd2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss = 0.05473279302709547\n",
            "Epoch 1000: Loss = 0.016987335175531224\n",
            "Epoch 2000: Loss = 0.016783818362044067\n",
            "Epoch 3000: Loss = 0.016552965802726173\n",
            "Epoch 4000: Loss = 0.016276948498423913\n",
            "Epoch 5000: Loss = 0.016028449785255652\n",
            "Epoch 6000: Loss = 0.015847326781924676\n",
            "Epoch 7000: Loss = 0.015736949893686954\n",
            "Epoch 8000: Loss = 0.015675356427184376\n",
            "Epoch 9000: Loss = 0.01564003564355994\n",
            "Epoch 10000: Loss = 0.015616203161587948\n",
            "Epoch 11000: Loss = 0.015591082740378553\n",
            "Epoch 12000: Loss = 0.015571581692409962\n",
            "Epoch 13000: Loss = 0.015552124845016502\n",
            "Epoch 14000: Loss = 0.015532274722127716\n",
            "Epoch 15000: Loss = 0.01551221573266877\n",
            "Epoch 16000: Loss = 0.015492397832936489\n",
            "Epoch 17000: Loss = 0.015473242023697124\n",
            "Epoch 18000: Loss = 0.015454999410623248\n",
            "Epoch 19000: Loss = 0.01543775742779831\n",
            "Epoch 20000: Loss = 0.01542150360681808\n",
            "Epoch 21000: Loss = 0.015406179655764197\n",
            "Epoch 22000: Loss = 0.015391709108468852\n",
            "Epoch 23000: Loss = 0.015378007318917785\n",
            "Epoch 24000: Loss = 0.015364985126108354\n"
          ]
        }
      ],
      "source": [
        " # Treinamento da rede neural\n",
        "epochs = 25000\n",
        "losses, accuracies = train_neural_network(x_train, y_train.to_numpy().reshape(-1, 1), input_size, hidden_size, output_size, epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E91jUN-8WYpM"
      },
      "source": [
        "# Parte 9 - Gera Previsão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lpj6_40sE2WU"
      },
      "source": [
        "Após o treinamento, visualizamos a perda e a acurácia da rede:\n",
        "\n",
        "**Gráfico de Desempenho**: Plotamos a perda ao longo do tempo para visualizar o ajuste da rede aos dados de treinamento e avaliar se o modelo está convergindo ou sofrendo overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WwPEICdkWfDZ",
        "outputId": "0860f946-3601-482f-f835-5adf9c1734c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotar a evolução da perda e da acurácia ao longo das épocas\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dados_plotar = losses\n",
        "\n",
        "# Criando o gráfico\n",
        "plt.plot(dados_plotar)\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Perda')\n",
        "plt.title('Evolução da perda à passagem de épocas')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.float64(0.05473279302709547),\n",
              " np.float64(0.024434505708496403),\n",
              " np.float64(0.022068314873643646),\n",
              " np.float64(0.021661136976419994),\n",
              " np.float64(0.021521909091058517),\n",
              " np.float64(0.021435610155782093),\n",
              " np.float64(0.021359539434459347),\n",
              " np.float64(0.021286183329114944),\n",
              " np.float64(0.021214153613402266),\n",
              " np.float64(0.02114320506869296),\n",
              " np.float64(0.021073301618700413),\n",
              " np.float64(0.02100444402301425),\n",
              " np.float64(0.020936639711359645),\n",
              " np.float64(0.02086989664457112),\n",
              " np.float64(0.020804222409024072),\n",
              " np.float64(0.02073962390278566),\n",
              " np.float64(0.02067610728229621),\n",
              " np.float64(0.020613677898523673),\n",
              " np.float64(0.020552340260905227),\n",
              " np.float64(0.02049209800019244),\n",
              " np.float64(0.020432953839718784),\n",
              " np.float64(0.02037490957076776),\n",
              " np.float64(0.020317966033684114),\n",
              " np.float64(0.02026212310395908),\n",
              " np.float64(0.02020737968347288),\n",
              " np.float64(0.02015373369665484),\n",
              " np.float64(0.020101182091456168),\n",
              " np.float64(0.020049720844941468),\n",
              " np.float64(0.01999934497330886),\n",
              " np.float64(0.019950048546117444),\n",
              " np.float64(0.01990182470448697),\n",
              " np.float64(0.019854665683016838),\n",
              " np.float64(0.019808562835158805),\n",
              " np.float64(0.019763506661766392),\n",
              " np.float64(0.01971948684253563),\n",
              " np.float64(0.019676492270045823),\n",
              " np.float64(0.019634511086105415),\n",
              " np.float64(0.01959353072010711),\n",
              " np.float64(0.01955353792909756),\n",
              " np.float64(0.019514518839270537),\n",
              " np.float64(0.019476458988597994),\n",
              " np.float64(0.019439343370320876),\n",
              " np.float64(0.01940315647703099),\n",
              " np.float64(0.019367882345085716),\n",
              " np.float64(0.019333504599109846),\n",
              " np.float64(0.019300006496351968),\n",
              " np.float64(0.019267370970677242),\n",
              " np.float64(0.01923558067599354),\n",
              " np.float64(0.019204618028923617),\n",
              " np.float64(0.019174465250552025),\n",
              " np.float64(0.019145104407092037),\n",
              " np.float64(0.019116517449334004),\n",
              " np.float64(0.019088686250753068),\n",
              " np.float64(0.019061592644170212),\n",
              " np.float64(0.01903521845687629),\n",
              " np.float64(0.019009545544144035),\n",
              " np.float64(0.018984555821067683),\n",
              " np.float64(0.01896023129268379),\n",
              " np.float64(0.018936554082340375),\n",
              " np.float64(0.018913506458293657),\n",
              " np.float64(0.018891070858523755),\n",
              " np.float64(0.018869229913771178),\n",
              " np.float64(0.01884796646880621),\n",
              " np.float64(0.01882726360195204),\n",
              " np.float64(0.018807104642890964),\n",
              " np.float64(0.01878747318879007),\n",
              " np.float64(0.018768353118789428),\n",
              " np.float64(0.01874972860690128),\n",
              " np.float64(0.018731584133373634),\n",
              " np.float64(0.01871390449457575),\n",
              " np.float64(0.01869667481146615),\n",
              " np.float64(0.018679880536706717),\n",
              " np.float64(0.018663507460488057),\n",
              " np.float64(0.018647541715133144),\n",
              " np.float64(0.01863196977854669),\n",
              " np.float64(0.01861677847657839),\n",
              " np.float64(0.018601954984367827),\n",
              " np.float64(0.01858748682673847),\n",
              " np.float64(0.018573361877707244),\n",
              " np.float64(0.01855956835917499),\n",
              " np.float64(0.018546094838861604),\n",
              " np.float64(0.01853293022754792),\n",
              " np.float64(0.018520063775684575),\n",
              " np.float64(0.018507485069425816),\n",
              " np.float64(0.01849518402614411),\n",
              " np.float64(0.018483150889478998),\n",
              " np.float64(0.018471376223971266),\n",
              " np.float64(0.018459850909330885),\n",
              " np.float64(0.018448566134384833),\n",
              " np.float64(0.018437513390748225),\n",
              " np.float64(0.018426684466259727),\n",
              " np.float64(0.018416071438219696),\n",
              " np.float64(0.01840566666646699),\n",
              " np.float64(0.018395462786328032),\n",
              " np.float64(0.018385452701469265),\n",
              " np.float64(0.018375629576681908),\n",
              " np.float64(0.018365986830625597),\n",
              " np.float64(0.01835651812855548),\n",
              " np.float64(0.018347217375055125),\n",
              " np.float64(0.018338078706795758),\n",
              " np.float64(0.018329096485340396),\n",
              " np.float64(0.01832026529000958),\n",
              " np.float64(0.018311579910823952),\n",
              " np.float64(0.01830303534153696),\n",
              " np.float64(0.018294626772769832),\n",
              " np.float64(0.018286349585259286),\n",
              " np.float64(0.018278199343227126),\n",
              " np.float64(0.018270171787879864),\n",
              " np.float64(0.018262262831044984),\n",
              " np.float64(0.018254468548949784),\n",
              " np.float64(0.018246785176147313),\n",
              " np.float64(0.01823920909959343),\n",
              " np.float64(0.01823173685287781),\n",
              " np.float64(0.018224365110611165),\n",
              " np.float64(0.018217090682970102),\n",
              " np.float64(0.018209910510400516),\n",
              " np.float64(0.01820282165847972),\n",
              " np.float64(0.018195821312936997),\n",
              " np.float64(0.018188906774831887),\n",
              " np.float64(0.01818207545588891),\n",
              " np.float64(0.018175324873987233),\n",
              " np.float64(0.01816865264880329),\n",
              " np.float64(0.01816205649760416),\n",
              " np.float64(0.018155534231189246),\n",
              " np.float64(0.018149083749977497),\n",
              " np.float64(0.01814270304023728),\n",
              " np.float64(0.01813639017045587),\n",
              " np.float64(0.018130143287845287),\n",
              " np.float64(0.018123960614981244),\n",
              " np.float64(0.018117840446571682),\n",
              " np.float64(0.018111781146351535),\n",
              " np.float64(0.01810578114410012),\n",
              " np.float64(0.01809983893277762),\n",
              " np.float64(0.01809395306577707),\n",
              " np.float64(0.018088122154288306),\n",
              " np.float64(0.018082344864770238),\n",
              " np.float64(0.01807661991652799),\n",
              " np.float64(0.018070946079391297),\n",
              " np.float64(0.018065322171490792),\n",
              " np.float64(0.01805974705712862),\n",
              " np.float64(0.018054219644740157),\n",
              " np.float64(0.0180487388849434),\n",
              " np.float64(0.018043303768672837),\n",
              " np.float64(0.018037913325394606),\n",
              " np.float64(0.01803256662139987),\n",
              " np.float64(0.01802726275817331),\n",
              " np.float64(0.018022000870833856),\n",
              " np.float64(0.018016780126644757),\n",
              " np.float64(0.018011599723590187),\n",
              " np.float64(0.018006458889015704),\n",
              " np.float64(0.018001356878329922),\n",
              " np.float64(0.01799629297376487),\n",
              " np.float64(0.01799126648319255),\n",
              " np.float64(0.01798627673899535),\n",
              " np.float64(0.01798132309698798),\n",
              " np.float64(0.01797640493538876),\n",
              " np.float64(0.017971521653838057),\n",
              " np.float64(0.017966672672461884),\n",
              " np.float64(0.017961857430978626),\n",
              " np.float64(0.017957075387846983),\n",
              " np.float64(0.01795232601945335),\n",
              " np.float64(0.017947608819336797),\n",
              " np.float64(0.017942923297449984),\n",
              " np.float64(0.017938268979454428),\n",
              " np.float64(0.017933645406048464),\n",
              " np.float64(0.017929052132326498),\n",
              " np.float64(0.017924488727168047),\n",
              " np.float64(0.017919954772655254),\n",
              " np.float64(0.01791544986351748),\n",
              " np.float64(0.017910973606601807),\n",
              " np.float64(0.017906525620368145),\n",
              " np.float64(0.017902105534407884),\n",
              " np.float64(0.0178977129889849),\n",
              " np.float64(0.01789334763459795),\n",
              " np.float64(0.017889009131563355),\n",
              " np.float64(0.017884697149617056),\n",
              " np.float64(0.017880411367535164),\n",
              " np.float64(0.017876151472772026),\n",
              " np.float64(0.017871917161115036),\n",
              " np.float64(0.0178677081363554),\n",
              " np.float64(0.01786352410997406),\n",
              " np.float64(0.017859364800842038),\n",
              " np.float64(0.017855229934934554),\n",
              " np.float64(0.017851119245058233),\n",
              " np.float64(0.01784703247059073),\n",
              " np.float64(0.017842969357232258),\n",
              " np.float64(0.017838929656768372),\n",
              " np.float64(0.01783491312684349),\n",
              " np.float64(0.01783091953074465),\n",
              " np.float64(0.01782694863719498),\n",
              " np.float64(0.017823000220156423),\n",
              " np.float64(0.01781907405864127),\n",
              " np.float64(0.017815169936532087),\n",
              " np.float64(0.017811287642409607),\n",
              " np.float64(0.017807426969388192),\n",
              " np.float64(0.017803587714958574),\n",
              " np.float64(0.017799769680837397),\n",
              " np.float64(0.01779597267282337),\n",
              " np.float64(0.017792196500659607),\n",
              " np.float64(0.017788440977901897),\n",
              " np.float64(0.017784705921792633),\n",
              " np.float64(0.017780991153140087),\n",
              " np.float64(0.01777729649620281),\n",
              " np.float64(0.017773621778578916),\n",
              " np.float64(0.017769966831099958),\n",
              " np.float64(0.017766331487729256),\n",
              " np.float64(0.017762715585464398),\n",
              " np.float64(0.017759118964243776),\n",
              " np.float64(0.017755541466856886),\n",
              " np.float64(0.0177519829388583),\n",
              " np.float64(0.017748443228485095),\n",
              " np.float64(0.017744922186577538),\n",
              " np.float64(0.017741419666502965),\n",
              " np.float64(0.017737935524082607),\n",
              " np.float64(0.017734469617521332),\n",
              " np.float64(0.017731021807340014),\n",
              " np.float64(0.01772759195631059),\n",
              " np.float64(0.01772417992939354),\n",
              " np.float64(0.01772078559367774),\n",
              " np.float64(0.017717408818322573),\n",
              " np.float64(0.017714049474502162),\n",
              " np.float64(0.01771070743535172),\n",
              " np.float64(0.017707382575915753),\n",
              " np.float64(0.017704074773098252),\n",
              " np.float64(0.01770078390561459),\n",
              " np.float64(0.01769750985394513),\n",
              " np.float64(0.017694252500290508),\n",
              " np.float64(0.017691011728528445),\n",
              " np.float64(0.017687787424172034),\n",
              " np.float64(0.01768457947432949),\n",
              " np.float64(0.017681387767665233),\n",
              " np.float64(0.017678212194362282),\n",
              " np.float64(0.01767505264608589),\n",
              " np.float64(0.017671909015948402),\n",
              " np.float64(0.01766878119847522),\n",
              " np.float64(0.01766566908957189),\n",
              " np.float64(0.017662572586492214),\n",
              " np.float64(0.017659491587807396),\n",
              " np.float64(0.01765642599337613),\n",
              " np.float64(0.017653375704315636),\n",
              " np.float64(0.017650340622973545),\n",
              " np.float64(0.017647320652900682),\n",
              " np.float64(0.017644315698824638),\n",
              " np.float64(0.017641325666624123),\n",
              " np.float64(0.017638350463304107),\n",
              " np.float64(0.01763538999697163),\n",
              " np.float64(0.017632444176812378),\n",
              " np.float64(0.017629512913067868),\n",
              " np.float64(0.0176265961170133),\n",
              " np.float64(0.01762369370093605),\n",
              " np.float64(0.017620805578114723),\n",
              " np.float64(0.017617931662798812),\n",
              " np.float64(0.017615071870188893),\n",
              " np.float64(0.017612226116417343),\n",
              " np.float64(0.017609394318529634),\n",
              " np.float64(0.017606576394466014),\n",
              " np.float64(0.017603772263043792),\n",
              " np.float64(0.01760098184393999),\n",
              " np.float64(0.017598205057674465),\n",
              " np.float64(0.017595441825593517),\n",
              " np.float64(0.017592692069853817),\n",
              " np.float64(0.017589955713406828),\n",
              " np.float64(0.01758723267998355),\n",
              " np.float64(0.017584522894079687),\n",
              " np.float64(0.017581826280941154),\n",
              " np.float64(0.01757914276654992),\n",
              " np.float64(0.01757647227761025),\n",
              " np.float64(0.017573814741535212),\n",
              " np.float64(0.017571170086433555),\n",
              " np.float64(0.017568538241096852),\n",
              " np.float64(0.017565919134986997),\n",
              " np.float64(0.01756331269822394),\n",
              " np.float64(0.017560718861573753),\n",
              " np.float64(0.01755813755643693),\n",
              " np.float64(0.017555568714836992),\n",
              " np.float64(0.017553012269409307),\n",
              " np.float64(0.01755046815339022),\n",
              " np.float64(0.017547936300606377),\n",
              " np.float64(0.0175454166454643),\n",
              " np.float64(0.017542909122940216),\n",
              " np.float64(0.017540413668570086),\n",
              " np.float64(0.017537930218439864),\n",
              " np.float64(0.017535458709175965),\n",
              " np.float64(0.017532999077935957),\n",
              " np.float64(0.017530551262399417),\n",
              " np.float64(0.01752811520075903),\n",
              " np.float64(0.01752569083171186),\n",
              " np.float64(0.017523278094450773),\n",
              " np.float64(0.017520876928656136),\n",
              " np.float64(0.017518487274487578),\n",
              " np.float64(0.017516109072576017),\n",
              " np.float64(0.017513742264015808),\n",
              " np.float64(0.01751138679035706),\n",
              " np.float64(0.017509042593598152),\n",
              " np.float64(0.017506709616178333),\n",
              " np.float64(0.017504387800970578),\n",
              " np.float64(0.017502077091274475),\n",
              " np.float64(0.01749977743080937),\n",
              " np.float64(0.017497488763707575),\n",
              " np.float64(0.01749521103450777),\n",
              " np.float64(0.017492944188148493),\n",
              " np.float64(0.017490688169961823),\n",
              " np.float64(0.017488442925667123),\n",
              " np.float64(0.01748620840136498),\n",
              " np.float64(0.017483984543531214),\n",
              " np.float64(0.017481771299011063),\n",
              " np.float64(0.01747956861501342),\n",
              " np.float64(0.01747737643910527),\n",
              " np.float64(0.017475194719206163),\n",
              " np.float64(0.017473023403582852),\n",
              " np.float64(0.01747086244084402),\n",
              " np.float64(0.017468711779935114),\n",
              " np.float64(0.017466571370133292),\n",
              " np.float64(0.01746444116104246),\n",
              " np.float64(0.017462321102588448),\n",
              " np.float64(0.017460211145014212),\n",
              " np.float64(0.01745811123887522),\n",
              " np.float64(0.017456021335034853),\n",
              " np.float64(0.01745394138465997),\n",
              " np.float64(0.01745187133921651),\n",
              " np.float64(0.017449811150465205),\n",
              " np.float64(0.017447760770457385),\n",
              " np.float64(0.017445720151530862),\n",
              " np.float64(0.017443689246305894),\n",
              " np.float64(0.017441668007681245),\n",
              " np.float64(0.01743965638883031),\n",
              " np.float64(0.01743765434319732),\n",
              " np.float64(0.017435661824493662),\n",
              " np.float64(0.0174336787866942),\n",
              " np.float64(0.017431705184033745),\n",
              " np.float64(0.017429740971003558),\n",
              " np.float64(0.017427786102347936),\n",
              " np.float64(0.017425840533060864),\n",
              " np.float64(0.017423904218382743),\n",
              " np.float64(0.01742197711379719),\n",
              " np.float64(0.01742005917502785),\n",
              " np.float64(0.01741815035803539),\n",
              " np.float64(0.017416250619014438),\n",
              " np.float64(0.01741435991439063),\n",
              " np.float64(0.017412478200817743),\n",
              " np.float64(0.01741060543517485),\n",
              " np.float64(0.01740874157456355),\n",
              " np.float64(0.017406886576305267),\n",
              " np.float64(0.017405040397938575),\n",
              " np.float64(0.017403202997216604),\n",
              " np.float64(0.017401374332104508),\n",
              " np.float64(0.017399554360776948),\n",
              " np.float64(0.017397743041615663),\n",
              " np.float64(0.017395940333207082),\n",
              " np.float64(0.01739414619433999),\n",
              " np.float64(0.01739236058400323),\n",
              " np.float64(0.017390583461383457),\n",
              " np.float64(0.01738881478586295),\n",
              " np.float64(0.017387054517017483),\n",
              " np.float64(0.01738530261461419),\n",
              " np.float64(0.017383559038609532),\n",
              " np.float64(0.01738182374914729),\n",
              " np.float64(0.017380096706556554),\n",
              " np.float64(0.017378377871349864),\n",
              " np.float64(0.01737666720422125),\n",
              " np.float64(0.017374964666044452),\n",
              " np.float64(0.01737327021787106),\n",
              " np.float64(0.017371583820928793),\n",
              " np.float64(0.017369905436619735),\n",
              " np.float64(0.01736823502651867),\n",
              " np.float64(0.017366572552371402),\n",
              " np.float64(0.01736491797609317),\n",
              " np.float64(0.01736327125976703),\n",
              " np.float64(0.017361632365642334),\n",
              " np.float64(0.01736000125613319),\n",
              " np.float64(0.01735837789381701),\n",
              " np.float64(0.017356762241433045),\n",
              " np.float64(0.017355154261880952),\n",
              " np.float64(0.017353553918219442),\n",
              " np.float64(0.01735196117366489),\n",
              " np.float64(0.017350375991590044),\n",
              " np.float64(0.0173487983355227),\n",
              " np.float64(0.017347228169144448),\n",
              " np.float64(0.017345665456289426),\n",
              " np.float64(0.01734411016094312),\n",
              " np.float64(0.01734256224724116),\n",
              " np.float64(0.017341021679468185),\n",
              " np.float64(0.017339488422056685),\n",
              " np.float64(0.017337962439585918),\n",
              " np.float64(0.017336443696780803),\n",
              " np.float64(0.017334932158510882),\n",
              " np.float64(0.017333427789789274),\n",
              " np.float64(0.017331930555771664),\n",
              " np.float64(0.01733044042175532),\n",
              " np.float64(0.01732895735317812),\n",
              " np.float64(0.017327481315617607),\n",
              " np.float64(0.017326012274790067),\n",
              " np.float64(0.01732455019654964),\n",
              " np.float64(0.017323095046887397),\n",
              " np.float64(0.01732164679193052),\n",
              " np.float64(0.01732020539794145),\n",
              " np.float64(0.017318770831317037),\n",
              " np.float64(0.01731734305858776),\n",
              " np.float64(0.017315922046416927),\n",
              " np.float64(0.017314507761599915),\n",
              " np.float64(0.017313100171063404),\n",
              " np.float64(0.017311699241864653),\n",
              " np.float64(0.017310304941190773),\n",
              " np.float64(0.01730891723635803),\n",
              " np.float64(0.017307536094811143),\n",
              " np.float64(0.01730616148412264),\n",
              " np.float64(0.01730479337199217),\n",
              " np.float64(0.01730343172624588),\n",
              " np.float64(0.017302076514835785),\n",
              " np.float64(0.01730072770583915),\n",
              " np.float64(0.017299385267457883),\n",
              " np.float64(0.017298049168017963),\n",
              " np.float64(0.017296719375968855),\n",
              " np.float64(0.017295395859882958),\n",
              " np.float64(0.01729407858845504),\n",
              " np.float64(0.017292767530501716),\n",
              " np.float64(0.01729146265496091),\n",
              " np.float64(0.01729016393089137),\n",
              " np.float64(0.01728887132747212),\n",
              " np.float64(0.017287584814002),\n",
              " np.float64(0.01728630435989918),\n",
              " np.float64(0.017285029934700675),\n",
              " np.float64(0.01728376150806191),\n",
              " np.float64(0.01728249904975624),\n",
              " np.float64(0.017281242529674522),\n",
              " np.float64(0.017279991917824682),\n",
              " np.float64(0.0172787471843313),\n",
              " np.float64(0.017277508299435175),\n",
              " np.float64(0.017276275233492927),\n",
              " np.float64(0.017275047956976614),\n",
              " np.float64(0.017273826440473317),\n",
              " np.float64(0.017272610654684776),\n",
              " np.float64(0.017271400570427),\n",
              " np.float64(0.017270196158629916),\n",
              " np.float64(0.017268997390337004),\n",
              " np.float64(0.017267804236704928),\n",
              " np.float64(0.01726661666900321),\n",
              " np.float64(0.017265434658613882),\n",
              " np.float64(0.017264258177031144),\n",
              " np.float64(0.017263087195861053),\n",
              " np.float64(0.01726192168682118),\n",
              " np.float64(0.017260761621740315),\n",
              " np.float64(0.01725960697255814),\n",
              " np.float64(0.01725845771132493),\n",
              " np.float64(0.017257313810201267),\n",
              " np.float64(0.017256175241457703),\n",
              " np.float64(0.01725504197747452),\n",
              " np.float64(0.01725391399074142),\n",
              " np.float64(0.017252791253857234),\n",
              " np.float64(0.01725167373952967),\n",
              " np.float64(0.017250561420575017),\n",
              " np.float64(0.017249454269917894),\n",
              " np.float64(0.017248352260590974),\n",
              " np.float64(0.017247255365734734),\n",
              " np.float64(0.017246163558597188),\n",
              " np.float64(0.017245076812533632),\n",
              " np.float64(0.0172439951010064),\n",
              " np.float64(0.017242918397584635),\n",
              " np.float64(0.01724184667594398),\n",
              " np.float64(0.017240779909866433),\n",
              " np.float64(0.017239718073240026),\n",
              " np.float64(0.017238661140058627),\n",
              " np.float64(0.01723760908442171),\n",
              " np.float64(0.0172365618805341),\n",
              " np.float64(0.01723551950270578),\n",
              " np.float64(0.017234481925351625),\n",
              " np.float64(0.017233449122991216),\n",
              " np.float64(0.017232421070248582),\n",
              " np.float64(0.017231397741852016),\n",
              " np.float64(0.017230379112633833),\n",
              " np.float64(0.017229365157530156),\n",
              " np.float64(0.01722835585158071),\n",
              " np.float64(0.017227351169928608),\n",
              " np.float64(0.017226351087820124),\n",
              " np.float64(0.017225355580604514),\n",
              " np.float64(0.017224364623733765),\n",
              " np.float64(0.017223378192762432),\n",
              " np.float64(0.01722239626334739),\n",
              " np.float64(0.017221418811247665),\n",
              " np.float64(0.017220445812324188),\n",
              " np.float64(0.017219477242539638),\n",
              " np.float64(0.017218513077958204),\n",
              " np.float64(0.017217553294745395),\n",
              " np.float64(0.017216597869167842),\n",
              " np.float64(0.01721564677759309),\n",
              " np.float64(0.017214699996489398),\n",
              " np.float64(0.017213757502425545),\n",
              " np.float64(0.01721281927207062),\n",
              " np.float64(0.01721188528219384),\n",
              " np.float64(0.01721095550966433),\n",
              " np.float64(0.017210029931450935),\n",
              " np.float64(0.017209108524622034),\n",
              " np.float64(0.017208191266345308),\n",
              " np.float64(0.01720727813388757),\n",
              " np.float64(0.01720636910461457),\n",
              " np.float64(0.017205464155990773),\n",
              " np.float64(0.017204563265579165),\n",
              " np.float64(0.01720366641104108),\n",
              " np.float64(0.017202773570135974),\n",
              " np.float64(0.01720188472072123),\n",
              " np.float64(0.01720099984075198),\n",
              " np.float64(0.01720011890828087),\n",
              " np.float64(0.017199241901457895),\n",
              " np.float64(0.01719836879853017),\n",
              " np.float64(0.017197499577841762),\n",
              " np.float64(0.017196634217833448),\n",
              " np.float64(0.01719577269704255),\n",
              " np.float64(0.017194914994102712),\n",
              " np.float64(0.017194061087743705),\n",
              " np.float64(0.017193210956791227),\n",
              " np.float64(0.01719236458016669),\n",
              " np.float64(0.017191521936887028),\n",
              " np.float64(0.01719068300606447),\n",
              " np.float64(0.01718984776690637),\n",
              " np.float64(0.01718901619871497),\n",
              " np.float64(0.0171881882808872),\n",
              " np.float64(0.01718736399291448),\n",
              " np.float64(0.01718654331438251),\n",
              " np.float64(0.017185726224971047),\n",
              " np.float64(0.017184912704453704),\n",
              " np.float64(0.017184102732697753),\n",
              " np.float64(0.017183296289663887),\n",
              " np.float64(0.01718249335540603),\n",
              " np.float64(0.017181693910071107),\n",
              " np.float64(0.017180897933898844),\n",
              " np.float64(0.017180105407221553),\n",
              " np.float64(0.01717931631046389),\n",
              " np.float64(0.017178530624142683),\n",
              " np.float64(0.017177748328866673),\n",
              " np.float64(0.017176969405336324),\n",
              " np.float64(0.017176193834343576),\n",
              " np.float64(0.017175421596771663),\n",
              " np.float64(0.017174652673594852),\n",
              " np.float64(0.01717388704587825),\n",
              " np.float64(0.017173124694777556),\n",
              " np.float64(0.017172365601538862),\n",
              " np.float64(0.017171609747498415),\n",
              " np.float64(0.017170857114082384),\n",
              " np.float64(0.017170107682806655),\n",
              " np.float64(0.01716936143527657),\n",
              " np.float64(0.01716861835318674),\n",
              " np.float64(0.01716787841832077),\n",
              " np.float64(0.01716714161255107),\n",
              " np.float64(0.017166407917838588),\n",
              " np.float64(0.01716567731623261),\n",
              " np.float64(0.01716494978987049),\n",
              " np.float64(0.01716422532097745),\n",
              " np.float64(0.017163503891866324),\n",
              " np.float64(0.017162785484937323),\n",
              " np.float64(0.017162070082677807),\n",
              " np.float64(0.017161357667662032),\n",
              " np.float64(0.01716064822255093),\n",
              " np.float64(0.017159941730091846),\n",
              " np.float64(0.01715923817311832),\n",
              " np.float64(0.017158537534549823),\n",
              " np.float64(0.01715783979739153),\n",
              " np.float64(0.01715714494473406),\n",
              " np.float64(0.017156452959753255),\n",
              " np.float64(0.017155763825709904),\n",
              " np.float64(0.017155077525949528),\n",
              " np.float64(0.0171543940439021),\n",
              " np.float64(0.017153713363081826),\n",
              " np.float64(0.017153035467086866),\n",
              " np.float64(0.017152360339599125),\n",
              " np.float64(0.017151687964383943),\n",
              " np.float64(0.0171510183252899),\n",
              " np.float64(0.017150351406248536),\n",
              " np.float64(0.01714968719127409),\n",
              " np.float64(0.017149025664463267),\n",
              " np.float64(0.017148366809994965),\n",
              " np.float64(0.01714771061213003),\n",
              " np.float64(0.017147057055210996),\n",
              " np.float64(0.017146406123661813),\n",
              " np.float64(0.01714575780198761),\n",
              " np.float64(0.017145112074774434),\n",
              " np.float64(0.017144468926688968),\n",
              " np.float64(0.017143828342478296),\n",
              " np.float64(0.01714319030696962),\n",
              " np.float64(0.01714255480507003),\n",
              " np.float64(0.01714192182176619),\n",
              " np.float64(0.01714129134212413),\n",
              " np.float64(0.017140663351288936),\n",
              " np.float64(0.017140037834484517),\n",
              " np.float64(0.017139414777013324),\n",
              " np.float64(0.01713879416425609),\n",
              " np.float64(0.017138175981671555),\n",
              " np.float64(0.0171375602147962),\n",
              " np.float64(0.017136946849244),\n",
              " np.float64(0.017136335870706124),\n",
              " np.float64(0.017135727264950686),\n",
              " np.float64(0.017135121017822465),\n",
              " np.float64(0.017134517115242647),\n",
              " np.float64(0.01713391554320854),\n",
              " np.float64(0.017133316287793313),\n",
              " np.float64(0.01713271933514572),\n",
              " np.float64(0.01713212467148983),\n",
              " np.float64(0.01713153228312475),\n",
              " np.float64(0.01713094215642436),\n",
              " np.float64(0.017130354277837028),\n",
              " np.float64(0.017129768633885344),\n",
              " np.float64(0.017129185211165847),\n",
              " np.float64(0.017128603996348742),\n",
              " np.float64(0.01712802497617764),\n",
              " np.float64(0.01712744813746926),\n",
              " np.float64(0.017126873467113175),\n",
              " np.float64(0.01712630095207151),\n",
              " np.float64(0.017125730579378707),\n",
              " np.float64(0.017125162336141204),\n",
              " np.float64(0.01712459620953718),\n",
              " np.float64(0.017124032186816282),\n",
              " np.float64(0.017123470255299325),\n",
              " np.float64(0.017122910402378046),\n",
              " np.float64(0.017122352615514785),\n",
              " np.float64(0.017121796882242257),\n",
              " np.float64(0.01712124319016323),\n",
              " np.float64(0.01712069152695026),\n",
              " np.float64(0.017120141880345423),\n",
              " np.float64(0.01711959423816003),\n",
              " np.float64(0.017119048588274323),\n",
              " np.float64(0.017118504918637246),\n",
              " np.float64(0.017117963217266125),\n",
              " np.float64(0.017117423472246394),\n",
              " np.float64(0.017116885671731318),\n",
              " np.float64(0.01711634980394174),\n",
              " np.float64(0.017115815857165748),\n",
              " np.float64(0.01711528381975845),\n",
              " np.float64(0.017114753680141644),\n",
              " np.float64(0.01711422542680359),\n",
              " np.float64(0.017113699048298677),\n",
              " np.float64(0.017113174533247177),\n",
              " np.float64(0.017112651870334967),\n",
              " np.float64(0.01711213104831322),\n",
              " np.float64(0.01711161205599816),\n",
              " np.float64(0.017111094882270746),\n",
              " np.float64(0.017110579516076432),\n",
              " np.float64(0.017110065946424856),\n",
              " np.float64(0.01710955416238957),\n",
              " np.float64(0.017109044153107756),\n",
              " np.float64(0.01710853590777997),\n",
              " np.float64(0.01710802941566983),\n",
              " np.float64(0.01710752466610375),\n",
              " np.float64(0.017107021648470673),\n",
              " np.float64(0.017106520352221773),\n",
              " np.float64(0.01710602076687018),\n",
              " np.float64(0.01710552288199072),\n",
              " np.float64(0.01710502668721962),\n",
              " np.float64(0.01710453217225422),\n",
              " np.float64(0.01710403932685272),\n",
              " np.float64(0.017103548140833886),\n",
              " np.float64(0.017103058604076786),\n",
              " np.float64(0.01710257070652049),\n",
              " np.float64(0.017102084438163807),\n",
              " np.float64(0.01710159978906503),\n",
              " np.float64(0.017101116749341613),\n",
              " np.float64(0.01710063530916994),\n",
              " np.float64(0.01710015545878502),\n",
              " np.float64(0.01709967718848022),\n",
              " np.float64(0.017099200488607),\n",
              " np.float64(0.01709872534957463),\n",
              " np.float64(0.017098251761849904),\n",
              " np.float64(0.0170977797159569),\n",
              " np.float64(0.01709730920247666),\n",
              " np.float64(0.01709684021204697),\n",
              " np.float64(0.017096372735362034),\n",
              " np.float64(0.017095906763172245),\n",
              " np.float64(0.017095442286283888),\n",
              " np.float64(0.01709497929555888),\n",
              " np.float64(0.01709451778191449),\n",
              " np.float64(0.017094057736323085),\n",
              " np.float64(0.017093599149811834),\n",
              " np.float64(0.017093142013462473),\n",
              " np.float64(0.017092686318411),\n",
              " np.float64(0.017092232055847437),\n",
              " np.float64(0.01709177921701554),\n",
              " np.float64(0.017091327793212537),\n",
              " np.float64(0.017090877775788875),\n",
              " np.float64(0.01709042915614794),\n",
              " np.float64(0.017089981925745793),\n",
              " np.float64(0.017089536076090896),\n",
              " np.float64(0.017089091598743878),\n",
              " np.float64(0.01708864848531723),\n",
              " np.float64(0.01708820672747507),\n",
              " np.float64(0.01708776631693288),\n",
              " np.float64(0.017087327245457213),\n",
              " np.float64(0.017086889504865477),\n",
              " np.float64(0.017086453087025635),\n",
              " np.float64(0.017086017983855967),\n",
              " np.float64(0.017085584187324795),\n",
              " np.float64(0.017085151689450233),\n",
              " np.float64(0.017084720482299934),\n",
              " np.float64(0.01708429055799082),\n",
              " np.float64(0.01708386190868882),\n",
              " np.float64(0.017083434526608644),\n",
              " np.float64(0.017083008404013476),\n",
              " np.float64(0.017082583533214766),\n",
              " np.float64(0.017082159906571963),\n",
              " np.float64(0.017081737516492234),\n",
              " np.float64(0.017081316355430247),\n",
              " np.float64(0.017080896415887906),\n",
              " np.float64(0.017080477690414077),\n",
              " np.float64(0.01708006017160437),\n",
              " np.float64(0.017079643852100874),\n",
              " np.float64(0.017079228724591902),\n",
              " np.float64(0.017078814781811745),\n",
              " np.float64(0.017078402016540435),\n",
              " np.float64(0.017077990421603483),\n",
              " np.float64(0.01707757998987163),\n",
              " np.float64(0.017077170714260625),\n",
              " np.float64(0.017076762587730943),\n",
              " np.float64(0.01707635560328757),\n",
              " np.float64(0.01707594975397975),\n",
              " np.float64(0.01707554503290074),\n",
              " np.float64(0.01707514143318756),\n",
              " np.float64(0.01707473894802078),\n",
              " np.float64(0.017074337570624234),\n",
              " np.float64(0.01707393729426482),\n",
              " np.float64(0.01707353811225225),\n",
              " np.float64(0.01707314001793879),\n",
              " np.float64(0.01707274300471906),\n",
              " np.float64(0.01707234706602976),\n",
              " np.float64(0.01707195219534947),\n",
              " np.float64(0.01707155838619837),\n",
              " np.float64(0.017071165632138056),\n",
              " np.float64(0.017070773926771268),\n",
              " np.float64(0.01707038326374168),\n",
              " np.float64(0.01706999363673364),\n",
              " np.float64(0.017069605039471983),\n",
              " np.float64(0.01706921746572177),\n",
              " np.float64(0.017068830909288048),\n",
              " np.float64(0.017068445364015646),\n",
              " np.float64(0.01706806082378895),\n",
              " np.float64(0.01706767728253165),\n",
              " np.float64(0.017067294734206543),\n",
              " np.float64(0.017066913172815276),\n",
              " np.float64(0.01706653259239816),\n",
              " np.float64(0.017066152987033904),\n",
              " np.float64(0.01706577435083943),\n",
              " np.float64(0.017065396677969625),\n",
              " np.float64(0.01706501996261714),\n",
              " np.float64(0.017064644199012158),\n",
              " np.float64(0.01706426938142216),\n",
              " np.float64(0.01706389550415175),\n",
              " np.float64(0.017063522561542394),\n",
              " np.float64(0.017063150547972226),\n",
              " np.float64(0.017062779457855816),\n",
              " np.float64(0.017062409285643985),\n",
              " np.float64(0.01706204002582356),\n",
              " np.float64(0.017061671672917163),\n",
              " np.float64(0.017061304221483036),\n",
              " np.float64(0.017060937666114766),\n",
              " np.float64(0.017060572001441142),\n",
              " np.float64(0.01706020722212589),\n",
              " np.float64(0.01705984332286751),\n",
              " np.float64(0.017059480298399023),\n",
              " np.float64(0.017059118143487803),\n",
              " np.float64(0.017058756852935345),\n",
              " np.float64(0.017058396421577075),\n",
              " np.float64(0.017058036844282146),\n",
              " np.float64(0.017057678115953216),\n",
              " np.float64(0.017057320231526264),\n",
              " np.float64(0.01705696318597039),\n",
              " np.float64(0.017056606974287597),\n",
              " np.float64(0.0170562515915126),\n",
              " np.float64(0.017055897032712635),\n",
              " np.float64(0.017055543292987262),\n",
              " np.float64(0.017055190367468123),\n",
              " np.float64(0.01705483825131883),\n",
              " np.float64(0.017054486939734687),\n",
              " np.float64(0.01705413642794255),\n",
              " np.float64(0.017053786711200603),\n",
              " np.float64(0.01705343778479818),\n",
              " np.float64(0.017053089644055563),\n",
              " np.float64(0.017052742284323803),\n",
              " np.float64(0.017052395700984532),\n",
              " np.float64(0.01705204988944975),\n",
              " np.float64(0.017051704845161653),\n",
              " np.float64(0.017051360563592455),\n",
              " np.float64(0.01705101704024419),\n",
              " np.float64(0.01705067427064852),\n",
              " np.float64(0.01705033225036656),\n",
              " np.float64(0.01704999097498869),\n",
              " np.float64(0.017049650440134394),\n",
              " np.float64(0.01704931064145202),\n",
              " np.float64(0.01704897157461867),\n",
              " np.float64(0.01704863323533997),\n",
              " np.float64(0.017048295619349917),\n",
              " np.float64(0.01704795872241067),\n",
              " np.float64(0.017047622540312415),\n",
              " np.float64(0.017047287068873155),\n",
              " np.float64(0.01704695230393855),\n",
              " np.float64(0.017046618241381713),\n",
              " np.float64(0.017046284877103097),\n",
              " np.float64(0.017045952207030257),\n",
              " np.float64(0.017045620227117714),\n",
              " np.float64(0.017045288933346774),\n",
              " np.float64(0.01704495832172535),\n",
              " np.float64(0.017044628388287804),\n",
              " np.float64(0.017044299129094775),\n",
              " np.float64(0.01704397054023301),\n",
              " np.float64(0.017043642617815186),\n",
              " np.float64(0.017043315357979764),\n",
              " np.float64(0.017042988756890812),\n",
              " np.float64(0.01704266281073783),\n",
              " np.float64(0.01704233751573561),\n",
              " np.float64(0.017042012868124057),\n",
              " np.float64(0.017041688864168025),\n",
              " np.float64(0.017041365500157165),\n",
              " np.float64(0.017041042772405757),\n",
              " np.float64(0.017040720677252565),\n",
              " np.float64(0.017040399211060653),\n",
              " np.float64(0.017040078370217246),\n",
              " np.float64(0.017039758151133573),\n",
              " np.float64(0.0170394385502447),\n",
              " np.float64(0.017039119564009386),\n",
              " np.float64(0.017038801188909915),\n",
              " np.float64(0.01703848342145196),\n",
              " np.float64(0.017038166258164414),\n",
              " np.float64(0.017037849695599253),\n",
              " np.float64(0.01703753373033136),\n",
              " np.float64(0.017037218358958404),\n",
              " np.float64(0.01703690357810068),\n",
              " np.float64(0.01703658938440095),\n",
              " np.float64(0.017036275774524306),\n",
              " np.float64(0.017035962745158013),\n",
              " np.float64(0.017035650293011385),\n",
              " np.float64(0.017035338414815606),\n",
              " np.float64(0.017035027107323613),\n",
              " np.float64(0.01703471636730994),\n",
              " np.float64(0.017034406191570584),\n",
              " np.float64(0.01703409657692285),\n",
              " np.float64(0.017033787520205207),\n",
              " np.float64(0.017033479018277172),\n",
              " np.float64(0.01703317106801915),\n",
              " np.float64(0.01703286366633229),\n",
              " np.float64(0.017032556810138363),\n",
              " np.float64(0.01703225049637962),\n",
              " np.float64(0.017031944722018653),\n",
              " np.float64(0.01703163948403824),\n",
              " np.float64(0.017031334779441257),\n",
              " np.float64(0.0170310306052505),\n",
              " np.float64(0.017030726958508564),\n",
              " np.float64(0.01703042383627772),\n",
              " np.float64(0.017030121235639777),\n",
              " np.float64(0.017029819153695933),\n",
              " np.float64(0.017029517587566684),\n",
              " np.float64(0.017029216534391656),\n",
              " np.float64(0.0170289159913295),\n",
              " np.float64(0.01702861595555774),\n",
              " np.float64(0.017028316424272688),\n",
              " np.float64(0.017028017394689256),\n",
              " np.float64(0.01702771886404089),\n",
              " np.float64(0.017027420829579407),\n",
              " np.float64(0.017027123288574884),\n",
              " np.float64(0.017026826238315525),\n",
              " np.float64(0.01702652967610756),\n",
              " np.float64(0.0170262335992751),\n",
              " np.float64(0.017025938005160012),\n",
              " np.float64(0.01702564289112183),\n",
              " np.float64(0.0170253482545376),\n",
              " np.float64(0.017025054092801785),\n",
              " np.float64(0.01702476040332612),\n",
              " np.float64(0.017024467183539525),\n",
              " np.float64(0.017024174430887974),\n",
              " np.float64(0.01702388214283436),\n",
              " np.float64(0.017023590316858416),\n",
              " np.float64(0.017023298950456567),\n",
              " np.float64(0.017023008041141836),\n",
              " np.float64(0.017022717586443716),\n",
              " np.float64(0.017022427583908078),\n",
              " np.float64(0.01702213803109703),\n",
              " np.float64(0.017021848925588827),\n",
              " np.float64(0.017021560264977746),\n",
              " np.float64(0.01702127204687399),\n",
              " np.float64(0.017020984268903572),\n",
              " np.float64(0.017020696928708206),\n",
              " np.float64(0.017020410023945182),\n",
              " np.float64(0.017020123552287297),\n",
              " np.float64(0.01701983751142271),\n",
              " np.float64(0.017019551899054852),\n",
              " np.float64(0.01701926671290233),\n",
              " np.float64(0.017018981950698796),\n",
              " np.float64(0.017018697610192875),\n",
              " np.float64(0.017018413689148023),\n",
              " np.float64(0.017018130185342473),\n",
              " np.float64(0.01701784709656908),\n",
              " np.float64(0.01701756442063526),\n",
              " np.float64(0.017017282155362867),\n",
              " np.float64(0.017017000298588096),\n",
              " np.float64(0.017016718848161392),\n",
              " np.float64(0.01701643780194734),\n",
              " np.float64(0.017016157157824584),\n",
              " np.float64(0.0170158769136857),\n",
              " np.float64(0.01701559706743712),\n",
              " np.float64(0.017015317616999034),\n",
              " np.float64(0.017015038560305288),\n",
              " np.float64(0.017014759895303298),\n",
              " np.float64(0.017014481619953937),\n",
              " np.float64(0.017014203732231458),\n",
              " np.float64(0.017013926230123395),\n",
              " np.float64(0.017013649111630464),\n",
              " np.float64(0.017013372374766484),\n",
              " np.float64(0.017013096017558273),\n",
              " np.float64(0.01701282003804556),\n",
              " np.float64(0.01701254443428089),\n",
              " np.float64(0.017012269204329557),\n",
              " np.float64(0.01701199434626948),\n",
              " np.float64(0.017011719858191134),\n",
              " np.float64(0.01701144573819746),\n",
              " np.float64(0.017011171984403783),\n",
              " np.float64(0.017010898594937707),\n",
              " np.float64(0.017010625567939034),\n",
              " np.float64(0.0170103529015597),\n",
              " np.float64(0.01701008059396367),\n",
              " np.float64(0.017009808643326844),\n",
              " np.float64(0.01700953704783699),\n",
              " np.float64(0.017009265805693653),\n",
              " np.float64(0.017008994915108083),\n",
              " np.float64(0.017008724374303126),\n",
              " np.float64(0.01700845418151317),\n",
              " np.float64(0.017008184334984047),\n",
              " np.float64(0.017007914832972964),\n",
              " np.float64(0.017007645673748406),\n",
              " np.float64(0.017007376855590065),\n",
              " np.float64(0.01700710837678877),\n",
              " np.float64(0.017006840235646394),\n",
              " np.float64(0.01700657243047577),\n",
              " np.float64(0.017006304959600642),\n",
              " np.float64(0.017006037821355555),\n",
              " np.float64(0.017005771014085805),\n",
              " np.float64(0.01700550453614733),\n",
              " np.float64(0.017005238385906674),\n",
              " np.float64(0.01700497256174088),\n",
              " np.float64(0.017004707062037435),\n",
              " np.float64(0.017004441885194174),\n",
              " np.float64(0.017004177029619233),\n",
              " np.float64(0.017003912493730962),\n",
              " np.float64(0.017003648275957843),\n",
              " np.float64(0.017003384374738435),\n",
              " np.float64(0.017003120788521293),\n",
              " np.float64(0.017002857515764892),\n",
              " np.float64(0.01700259455493757),\n",
              " np.float64(0.017002331904517446),\n",
              " np.float64(0.017002069562992356),\n",
              " np.float64(0.017001807528859776),\n",
              " np.float64(0.017001545800626766),\n",
              " np.float64(0.017001284376809884),\n",
              " np.float64(0.01700102325593514),\n",
              " np.float64(0.017000762436537902),\n",
              " np.float64(0.017000501917162854),\n",
              " np.float64(0.017000241696363917),\n",
              " np.float64(0.016999981772704176),\n",
              " np.float64(0.016999722144755838),\n",
              " np.float64(0.01699946281110013),\n",
              " np.float64(0.01699920377032727),\n",
              " np.float64(0.016998945021036393),\n",
              " np.float64(0.01699868656183546),\n",
              " np.float64(0.016998428391341233),\n",
              " np.float64(0.0169981705081792),\n",
              " np.float64(0.01699791291098349),\n",
              " np.float64(0.016997655598396836),\n",
              " np.float64(0.016997398569070513),\n",
              " np.float64(0.016997141821664258),\n",
              " np.float64(0.01699688535484623),\n",
              " np.float64(0.01699662916729293),\n",
              " np.float64(0.016996373257689157),\n",
              " np.float64(0.016996117624727934),\n",
              " np.float64(0.016995862267110473),\n",
              " np.float64(0.016995607183546084),\n",
              " np.float64(0.016995352372752133),\n",
              " np.float64(0.016995097833453994),\n",
              " np.float64(0.016994843564384972),\n",
              " np.float64(0.01699458956428625),\n",
              " np.float64(0.016994335831906852),\n",
              " np.float64(0.016994082366003554),\n",
              " np.float64(0.016993829165340854),\n",
              " np.float64(0.01699357622869091),\n",
              " np.float64(0.01699332355483347),\n",
              " np.float64(0.016993071142555837),\n",
              " np.float64(0.01699281899065281),\n",
              " np.float64(0.016992567097926622),\n",
              " np.float64(0.01699231546318689),\n",
              " np.float64(0.016992064085250558),\n",
              " np.float64(0.016991812962941857),\n",
              " np.float64(0.016991562095092245),\n",
              " np.float64(0.01699131148054034),\n",
              " np.float64(0.016991061118131895),\n",
              " np.float64(0.016990811006719727),\n",
              " np.float64(0.01699056114516367),\n",
              " np.float64(0.016990311532330535),\n",
              " np.float64(0.016990062167094037),\n",
              " np.float64(0.016989813048334766),\n",
              " np.float64(0.016989564174940134),\n",
              " np.float64(0.016989315545804316),\n",
              " np.float64(0.016989067159828203),\n",
              " np.float64(0.01698881901591937),\n",
              " np.float64(0.016988571112992),\n",
              " np.float64(0.016988323449966848),\n",
              " np.float64(0.016988076025771223),\n",
              " np.float64(0.016987828839338873),\n",
              " np.float64(0.016987581889610012),\n",
              " ...]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
